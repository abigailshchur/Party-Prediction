{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import csv\n",
    "from __future__ import print_function\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import re\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to go through all of our tweets and store them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "democrats = [];\n",
    "with open('./dem_tweets.txt', 'r') as f:\n",
    "    democrats = f.read().splitlines();\n",
    "    \n",
    "republicans = [];\n",
    "with open('./rep_tweets.txt', 'r') as f:\n",
    "    republicans = f.read().splitlines();\n",
    "    \n",
    "random.shuffle(republicans)\n",
    "republicans = republicans[0:len(democrats)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting relevant hashtags from tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=4000,\n",
    "                                stop_words='english')\n",
    "def removeHTTPS(l):\n",
    "    return map(lambda x: re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", x), l)\n",
    "\n",
    "def removeRT(l):\n",
    "    return map(lambda x: re.sub(r\"(RT )\", \"\", x), l)\n",
    "\n",
    "democrats = removeHTTPS(democrats)\n",
    "democrats = removeRT(democrats)\n",
    "\n",
    "republicans = removeHTTPS(republicans)\n",
    "republicans = removeRT(republicans)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Democrats:\n",
      "p2: 41304\n",
      "gopdebate: 14396\n",
      "actonclimate: 12996\n",
      "tcot: 11933\n",
      "obamacare: 11886\n",
      "gop: 11465\n",
      "sotu: 10223\n",
      "raisethewage: 9053\n",
      "getcovered: 8881\n",
      "demdebate: 8352\n",
      "\n",
      "Republicans:\n",
      "tcot: 158915\n",
      "teaparty: 53737\n",
      "gop: 31150\n",
      "tlot: 25147\n",
      "obamacare: 22124\n",
      "gophers: 13970\n",
      "gopdebate: 13509\n",
      "p2: 13062\n",
      "ff: 11620\n",
      "sgp: 11134\n"
     ]
    }
   ],
   "source": [
    "hashtags_dem_count = {};\n",
    "hashtags_dem_text = {};\n",
    "hashtags_rep_count = {};\n",
    "hashtags_rep_text = {};\n",
    "\n",
    "for tweet in democrats:\n",
    "    h = re.findall(r\"#(\\w+)\", tweet);\n",
    "    h = map(lambda x:x.lower(),h);\n",
    "    for i in h:\n",
    "        if hashtags_dem_count.get(i) is None:\n",
    "            hashtags_dem_count[i] = 1;\n",
    "            hashtags_dem_text[i] = [tweet];\n",
    "        else:\n",
    "            hashtags_dem_count[i] += 1;\n",
    "            hashtags_dem_text[i].append(tweet);\n",
    "            \n",
    "for tweet in republicans:\n",
    "    h = re.findall(r\"#(\\w+)\", tweet);\n",
    "    h = map(lambda x:x.lower(),h);\n",
    "    for i in h:\n",
    "        if hashtags_rep_count.get(i) is None:\n",
    "            hashtags_rep_count[i] = 1;\n",
    "            hashtags_rep_text[i] = [tweet];\n",
    "        else:\n",
    "            hashtags_rep_count[i] += 1;\n",
    "            hashtags_rep_text[i].append(tweet);\n",
    "            \n",
    "demHashtagCount = Counter(hashtags_dem_count);\n",
    "repHashtagCount = Counter(hashtags_rep_count);\n",
    "\n",
    "print(\"Democrats:\")\n",
    "for k, v in demHashtagCount.most_common(10):\n",
    "    print('%s: %i' % (k, v))\n",
    "    \n",
    "print(\"\")\n",
    "print(\"Republicans:\")\n",
    "for k, v in repHashtagCount.most_common(10):\n",
    "    print('%s: %i' % (k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popular Hashtags:\n",
      "tcot: 170848\n",
      "teaparty: 55641\n",
      "p2: 54366\n",
      "gop: 42615\n",
      "obamacare: 34010\n",
      "gopdebate: 27905\n",
      "tlot: 26603\n",
      "ff: 18710\n",
      "sotu: 16850\n",
      "obama: 14579\n",
      "demdebate: 11257\n",
      "uniteblue: 10452\n",
      "jobs: 10425\n",
      "scotus: 9679\n",
      "nhpolitics: 9154\n",
      "mapoli: 8970\n",
      "aca: 8117\n",
      "sayfie: 7882\n",
      "txlege: 7865\n",
      "utpol: 7715\n"
     ]
    }
   ],
   "source": [
    "num_hashtags = 20;\n",
    "\n",
    "d = [ seq[0] for seq in demHashtagCount.most_common(500) ]\n",
    "r = [ seq[0] for seq in repHashtagCount.most_common(500) ]\n",
    "\n",
    "intersection = list(set(d) & set(r));\n",
    "popular_hashtags = {};\n",
    "for i in intersection:\n",
    "    popular_hashtags[i] = hashtags_dem_count[i] + hashtags_rep_count[i];\n",
    "\n",
    "pop_h_counter = Counter(popular_hashtags);\n",
    "popular_hashtags = pop_h_counter.most_common(num_hashtags);\n",
    "print(\"Popular Hashtags:\")\n",
    "for k, v in popular_hashtags:\n",
    "    print('%s: %i' % (k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculations for first hashtag\n",
    "hashtag = popular_hashtags[0][0];\n",
    "dem_tweets0 = hashtags_dem_text[hashtag];\n",
    "rep_tweets0 = hashtags_rep_text[hashtag];\n",
    "num_dem = len(dem_tweets0);\n",
    "num_rep = len(rep_tweets0);\n",
    "\n",
    "# compute score of unigram u towards affiliation A\n",
    "p_dem = len(dem_tweets0)*1.0/(len(rep_tweets0) + len(dem_tweets0));\n",
    "p_rep = len(rep_tweets0)*1.0/(len(rep_tweets0) + len(dem_tweets0));\n",
    "\n",
    "count_vec = CountVectorizer(max_df=0.8,  stop_words='english', min_df = 0.0001)\n",
    "\n",
    "tweets_v = count_vec.fit_transform(dem_tweets0 + rep_tweets0).toarray();\n",
    "\n",
    "terms = count_vec.get_feature_names();\n",
    "\n",
    "term_dict = {}\n",
    "for i in range(len(terms)):\n",
    "    term_dict[terms[i]] = i\n",
    "    \n",
    "index_to_vocab = {i:v for i, v in enumerate(count_vec.get_feature_names())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abigailshchur/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: RuntimeWarning: divide by zero encountered in divide\n",
      "  app.launch_new_instance()\n",
      "/Users/abigailshchur/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  app.launch_new_instance()\n",
      "/Users/abigailshchur/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: RuntimeWarning: divide by zero encountered in divide\n",
      "/Users/abigailshchur/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "dem_tweets_v = tweets_v[0:num_dem,:];\n",
    "rep_tweets_v = tweets_v[num_dem:,:];\n",
    "sd = p_dem*np.log(np.divide(np.sum(dem_tweets_v, axis = 0),np.sum(rep_tweets_v, axis = 0)));\n",
    "sr = p_rep*np.log(np.divide(np.sum(rep_tweets_v, axis = 0), np.sum(dem_tweets_v, axis = 0)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "u_score = {};\n",
    "u_score_label = {};\n",
    "for i in range(0, len(sd)):\n",
    "    sdvalid = not math.isnan(sd[i]) and not math.isinf(sd[i]) and sd[i] !=0;\n",
    "    srvalid = not math.isnan(sr[i]) and not math.isinf(sr[i]) and sr[i] !=0;\n",
    "    if (sdvalid and srvalid):\n",
    "        if (sd[i] > sr[i]):\n",
    "            u_score[index_to_vocab[i]] = sd[i];\n",
    "            u_score_label[index_to_vocab[i]] = \"d\";\n",
    "        else:\n",
    "            u_score[index_to_vocab[i]] = sr[i];\n",
    "            u_score_label[index_to_vocab[i]] = \"r\";\n",
    "    elif (sdvalid):\n",
    "        u_score[index_to_vocab[i]] = sd[i];\n",
    "        u_score_label[index_to_vocab[i]] = \"d\";\n",
    "    elif (srvalid):\n",
    "        u_score[index_to_vocab[i]] = sr[i];\n",
    "        u_score_label[index_to_vocab[i]] = \"r\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mpscore_dem = [];\n",
    "mpscore_rep = [];\n",
    "\n",
    "for i in range(num_dem):\n",
    "    mpmax = float(\"-inf\");\n",
    "    text = dem_tweets_v[i,:];\n",
    "    notzero = np.nonzero(text)[0];\n",
    "    for j in notzero:\n",
    "        if (u_score.get(index_to_vocab[j]) is not None):\n",
    "            if (mpmax < u_score[index_to_vocab[j]]):\n",
    "                mpmax = u_score[index_to_vocab[j]]\n",
    "    if(math.isinf(mpmax)):\n",
    "        mpmax = float(\"inf\");\n",
    "    mpscore_dem.append(mpmax);\n",
    "\n",
    "for i in range(num_rep):\n",
    "    mpmax = float(\"-inf\");\n",
    "    text = rep_tweets_v[i,:];\n",
    "    notzero = np.nonzero(text)[0];\n",
    "    for j in notzero:\n",
    "        if (u_score.get(index_to_vocab[j]) is not None):\n",
    "            if (mpmax < u_score[index_to_vocab[j]]):\n",
    "                mpmax = u_score[index_to_vocab[j]]\n",
    "    if(math.isinf(mpmax)):\n",
    "        mpmax = float(\"inf\");\n",
    "    mpscore_rep.append(mpmax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#DumpTrump #UniteBlue #tcot \n",
      "0.0484133575203\n",
      "#p1 #p2 #p21 #cspj #tcot # ...\n",
      "0.0484133575203\n",
      "#p1 #p2 #p21 #cspj #tcot ...\n",
      "0.0484133575203\n",
      "Hey!  #tcot \n",
      "0.0484133575203\n",
      "#DumpTrump #tcot #UniteBlue #TNTweeters \n",
      "0.0484133575203\n",
      "#UniteBlue #tcot #CircusAct #DumpTrump\n",
      "0.0484133575203\n",
      "#DumpTrump #UniteBlue #tcot #ClownCar \n",
      "0.0484133575203\n",
      "#DumpTrump #NoMoreBushes #YouCruzYouLose #RubioRuse #UniteBlue #tcot\n",
      "0.0484133575203\n",
      "#DumpTrump #VoteBlue #RegisterToVote #UniteBlue #tcot\n",
      "0.0484133575203\n",
      "#dumptrump #lolgop #tcot \n",
      "0.0484133575203\n"
     ]
    }
   ],
   "source": [
    "all_mp_scores = np.array(mpscore_dem + mpscore_rep);\n",
    "all_tweets = dem_tweets0 + rep_tweets0;\n",
    "neutral_tweets = all_mp_scores.argsort()[:10];\n",
    "for i in neutral_tweets:\n",
    "    print(all_tweets[i])\n",
    "    print(all_mp_scores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To be the smartest president EVAR, Obama is really stupid.  What does that say about Thomas Jefferson?  #tcot #sgp #teaparty #hhrs\n",
      "6.95742770418\n",
      "So much angst about how we can better keep track of sex offenders - how about we don't let them out of jail? #tcot #hhrs\n",
      "6.95742770418\n",
      " \"Stand for freedom, and the American people will stand with you\".  Mike Pence #tcot #teaparty #sgp #sot #hhrs\n",
      "6.95742770418\n",
      "Pelosi can't keep promise to \"drain the swamp\"   #gop #tcot #iamthemob #sgp #hcr #hhrs #glennbeck\n",
      "6.95742770418\n",
      "So President/CEO Obama fires Wagoner, sets employee pay, pulls GM out of NASCAR .. people still dont have a problem with this?? #tcot #hhrs\n",
      "6.95742770418\n",
      "really think we can \"cut the rate of growth of national health care spending by 1.5 percentage points each year\" I say no way #tcot #hhrs\n",
      "6.95742770418\n",
      " Influential liberal sees the light on Obama  #news #tcot #gop #hhrs\n",
      "6.95742770418\n",
      " read both speaches from today .. one used fear a LOT ... and it wasn't Cheney. That's the BHO MO - crisis etc #tcot #hhrs\n",
      "6.95742770418\n",
      "Red Cross bans Christmas, says \"we must not upset Moslems\"  #tcot #sgp #hhrs\n",
      "6.95742770418\n",
      "The Day Obamacare Died:    #obama #tcot #tlot #912 #liberty #teaparty #rkba #nra #revolution #hhrs #sgp #c4L #p2\n",
      "6.95742770418\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_mp_scores)):\n",
    "    if (math.isinf(all_mp_scores[i])):\n",
    "        all_mp_scores[i] = float(\"-inf\");\n",
    "not_neutral_tweets = all_mp_scores.argsort()[::-1][:10]\n",
    "for i in not_neutral_tweets:\n",
    "    print(all_tweets[i])\n",
    "    print(all_mp_scores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
